[Back to front page](topics/backend-software-engineering/backend-software-engineering.md)

# Caching

Caching is a technique used in computing to store and retrieve frequently accessed data quickly, reducing the need to fetch it from the original, slower source repeatedly.

It involves keeping a copy of data in a location thatâ€™s faster to access than its primary storage. Caching can occur at various levels, including browser caching, application-level caching, and database caching. It significantly improves performance by reducing latency, decreasing network traffic, and lowering the load on servers or databases.

Common caching strategies include time-based expiration, least recently used (LRU) algorithms, and write-through or write-back policies. While caching enhances speed and efficiency, it also introduces challenges in maintaining data consistency and freshness.

Effective cache management is crucial in balancing performance gains with the need for up-to-date information in dynamic systems.

## Linked materials

- [Client-side caching](client-side-caching.md)
- [CDN caching](cdn-caching.md)
- [Server-side caching](server-side-caching.md)

## Available Resources

- [What is Caching (AWS)](https://aws.amazon.com/caching/)
- [Caching (Cloudflare)](https://www.cloudflare.com/learning/cdn/what-is-caching/)